{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"Customer_Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= data.drop(labels=[\"RowNumber\",\"CustomerId\",\"Surname\"],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =data[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  #LAbelEncode,OneHotEncode(pd.getdummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab= LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Geography\"]=lab.fit_transform(X[\"Geography\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     2\n",
       "2     0\n",
       "3     0\n",
       "4     2\n",
       "5     2\n",
       "6     0\n",
       "7     1\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    2\n",
       "12    0\n",
       "13    0\n",
       "14    2\n",
       "15    1\n",
       "16    1\n",
       "17    2\n",
       "18    2\n",
       "19    0\n",
       "Name: Geography, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"Geography\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Gender\"]= lab.fit_transform(X[\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     1\n",
       "6     1\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    1\n",
       "16    1\n",
       "17    0\n",
       "18    1\n",
       "19    0\n",
       "Name: Gender, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"Gender\"].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE STANDARDIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= StandardScaler()\n",
    "X_train= sc.fit_transform(X_train)\n",
    "X_test= sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16958176,  1.51919821, -1.09168714, ..., -1.03227043,\n",
       "         1.10643166, -0.50624244],\n",
       "       [-2.30455945,  0.3131264 ,  0.91601335, ...,  0.9687384 ,\n",
       "        -0.74866447, -0.50624244],\n",
       "       [-1.19119591, -0.89294542, -1.09168714, ..., -1.03227043,\n",
       "         1.48533467, -0.50624244],\n",
       "       ...,\n",
       "       [ 0.9015152 , -0.89294542,  0.91601335, ..., -1.03227043,\n",
       "         1.41231994, -0.50624244],\n",
       "       [-0.62420521,  1.51919821, -1.09168714, ...,  0.9687384 ,\n",
       "         0.84432121, -0.50624244],\n",
       "       [-0.28401079,  0.3131264 , -1.09168714, ..., -1.03227043,\n",
       "         0.32472465,  1.97533814]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD AN ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(X.shape[1],activation=\"relu\",input_dim=X.shape[1]))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 2s 351us/sample - loss: 3.4005e-07 - accuracy: 1.0000 - val_loss: 4.2342e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 2s 340us/sample - loss: 2.3646e-07 - accuracy: 1.0000 - val_loss: 3.2668e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 2s 318us/sample - loss: 1.6573e-07 - accuracy: 1.0000 - val_loss: 2.5124e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 2s 333us/sample - loss: 1.1838e-07 - accuracy: 1.0000 - val_loss: 1.8311e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 2s 342us/sample - loss: 8.2243e-08 - accuracy: 1.0000 - val_loss: 1.2891e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 2s 332us/sample - loss: 5.8348e-08 - accuracy: 1.0000 - val_loss: 9.5919e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 2s 319us/sample - loss: 4.0994e-08 - accuracy: 1.0000 - val_loss: 7.5185e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 2s 324us/sample - loss: 2.8912e-08 - accuracy: 1.0000 - val_loss: 5.2542e-08 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 2s 327us/sample - loss: 2.0584e-08 - accuracy: 1.0000 - val_loss: 4.0323e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 2s 348us/sample - loss: 1.4484e-08 - accuracy: 1.0000 - val_loss: 3.1189e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "histor=model.fit(X_train,y_train.to_numpy(),batch_size=10,epochs=10,verbose=1,validation_split=0.2) #verbose gives the training visualization of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 68us/sample - loss: 6.3497e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.349748795844712e-08, 1.0]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=cm(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,309\n",
      "Trainable params: 18,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTTING LEARNING CURVE AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module tensorflow.python.keras.engine.sequential object:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.training.Model)\n",
      " |  Linear stack of layers.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      layers: list of layers to add to the model.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  # Afterwards, we do automatic shape inference:\n",
      " |  model.add(Dense(32))\n",
      " |  \n",
      " |  # This is identical to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_dim=500))\n",
      " |  \n",
      " |  # And to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, batch_input_shape=(None, 500)))\n",
      " |  \n",
      " |  # Note that you can also omit the `input_shape` argument:\n",
      " |  # In that case the model gets built the first time you call `fit` (or other\n",
      " |  # training and evaluation methods).\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.compile(optimizer=optimizer, loss=loss)\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  \n",
      " |  # Note that when using this delayed-build pattern (no input shape specified),\n",
      " |  # the model doesn't have any weights until the first call\n",
      " |  # to a training/evaluation method (since it isn't yet built):\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns []\n",
      " |  \n",
      " |  # Whereas if you specify the input shape, the model gets built continuously\n",
      " |  # as you are adding layers:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  \n",
      " |  # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  # choose to manually build your model by calling `build(batch_input_shape)`:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.build((None, 500))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.network.Network\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      " |           are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, or TensorShape).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the network's input specs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, distribute=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |              `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |              function is any callable with the signature\n",
      " |              `scalar_loss = fn(y_true, y_pred)`. If the model has multiple\n",
      " |              outputs, you can use a different loss on each output by passing a\n",
      " |              dictionary or a list of losses. The loss value that will be\n",
      " |              minimized by the model will then be the sum of all individual\n",
      " |              losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |              and testing. Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          distribute: NOT SUPPORTED IN TF 2.0, please create and compile the\n",
      " |              model under distribution strategy scope instead of passing it to\n",
      " |              compile.\n",
      " |          **kwargs: Any additional arguments.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely).\n",
      " |            If `x` is a dataset, generator or\n",
      " |            `keras.utils.Sequence` instance, `y` should not be specified (since\n",
      " |            targets will be obtained from the iterator/dataset).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, instead pass\n",
      " |              sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |              If x is a `tf.data` dataset and `steps` is\n",
      " |              None, 'evaluate' will run until the dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.evaluate, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, datasets,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of a infinite dataset, it will run into a infinite loop.\n",
      " |              If 'validation_steps' is specified and only part of the dataset\n",
      " |              will be consumed, the evaluation will start from the beginning of\n",
      " |              the dataset at each epoch. This ensures that the same validation\n",
      " |              samples are used every time.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |          **kwargs: Used for backwards compatibility.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.fit, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.predict, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of metrics.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset `y` should\n",
      " |            not be specified (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |              supported when `x` is a dataset.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, `y` should not be specified\n",
      " |            (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample. In this case you should make sure to specify\n",
      " |            sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |            supported when `x` is a dataset.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  sample_weights\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model` is a compiled model ready to be used\n",
      " |      (unless the saved model was never compiled in the first place).\n",
      " |      \n",
      " |      Models built with the Sequential and Functional API can be saved to both the\n",
      " |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
      " |      SavedModel format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to SavedModel or H5 file to save the model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
      " |              to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X, and\n",
      " |              'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
      " |              options for saving to SavedModel.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the file to save the weights to. When saving\n",
      " |              in TensorFlow format, this is the prefix used for checkpoint files\n",
      " |              (multiple files are generated). Note that the '.h5' suffix causes\n",
      " |              weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1934df7e9b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histor.history[\"accuracy\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histor.history[\"loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcm= plot_confusion_matrix(conf_mat=mat,class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
